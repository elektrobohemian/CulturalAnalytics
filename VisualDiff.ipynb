{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cultural-proportion",
   "metadata": {},
   "source": [
    "https://pypi.org/project/ImageHash/\n",
    "\n",
    "https://stackoverflow.com/questions/998662/what-is-image-hashing-used-for (erklärt die Verfahren)\n",
    "\n",
    "M.Sc. thesis zum p-hash http://www.phash.org/docs/pubs/thesis_zauner.pdf\n",
    "\n",
    "noch mehr zu den Distanzen:\n",
    "\n",
    "https://tech.okcupid.com/evaluating-perceptual-image-hashes-okcupid/\n",
    "https://content-blockchain.org/research/testing-different-image-hash-functions/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "directed-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "# image hash dependencies\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import hamming\n",
    "from jellyfish import jaro_distance\n",
    "import scipy.cluster.hierarchy as scipycluster\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "comparison_base_ppn=\"PPN745219993\"\n",
    "basePath=\"/Users/david/src/python/StabiHacks/sbbget/sbbget_downloads.leske_mini/download_temp/\"\n",
    "#basePath=\"/Users/david/src/python/StabiHacks/sbbget/sbbget_downloads.leske/download_temp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "inside-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printLog(text):\n",
    "    now = str(datetime.now())\n",
    "    print(\"[\" + now + \"]\\t\" + text)\n",
    "    # forces to output the result of the print command immediately, see: http://stackoverflow.com/questions/230751/how-to-flush-output-of-python-print\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "arctic-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all subdirectories startings with PPN as each PPN stands for a different medium\n",
    "dirsPerPPN = dict()\n",
    "ppnDirs=[]\n",
    "for x in os.listdir(basePath):\n",
    "    if x.startswith(\"PPN\"):\n",
    "        dirsPerPPN[x]=[]\n",
    "        ppnDirs.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "polished-gravity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-03-16 14:43:55.510683]\tAnalysing directories and calculating image hashes...\n",
      "[2021-03-16 14:43:58.449171]\tDone.\n"
     ]
    }
   ],
   "source": [
    "# browse all directories below sbbGetBasePath and search for *_FULLTEXT and *_TIFF directories\n",
    "# and associate each with its PPN\n",
    "\n",
    "# each dictionary will use a PPN as key and an array of file paths (or the like) as value\n",
    "# base_ denote the values of comparison_base_ppn\n",
    "base_fulltextFilePaths = []\n",
    "base_jpgFilePaths = []\n",
    "base_jpgHashes=[]\n",
    "fulltextFilePaths = dict()\n",
    "jpgFilePaths = dict()\n",
    "jpgHashes=dict()\n",
    "\n",
    "printLog(\"Analysing directories and calculating image hashes...\")\n",
    "for ppn in ppnDirs:\n",
    "    if ppn==comparison_base_ppn:\n",
    "        pass\n",
    "    else:\n",
    "        fulltextFilePaths[ppn] = []\n",
    "        jpgFilePaths[ppn] = []\n",
    "        jpgHashes[ppn]=[]\n",
    "    for dirpath, dirnames, files in os.walk(basePath+ppn):\n",
    "        for name in files:\n",
    "            if dirpath.endswith(\"_FULLTEXT\"):\n",
    "                # if we found a fulltext directory, only add XML files, i.e., the ALTO candidate files\n",
    "                if name.endswith(\".xml\") or name.endswith(\".XML\"):\n",
    "                    if ppn==comparison_base_ppn:\n",
    "                        base_fulltextFilePaths.append(os.path.join(dirpath, name))\n",
    "                    else:\n",
    "                        fulltextFilePaths[ppn].append(os.path.join(dirpath, name))\n",
    "                    dirsPerPPN[ppn].append(os.path.join(dirpath, name))\n",
    "            if dirpath.endswith(\"_TIFF\"):\n",
    "                # if we found a image directory, only add JPEG files,\n",
    "                if name.endswith(\".jpg\") or name.endswith(\".JPG\"):\n",
    "                    tokens=dirpath.split(\"FILE_\")\n",
    "                    physicalID=tokens[1].replace(\"_TIFF\",\"\")\n",
    "\n",
    "                    hash=imagehash.phash(Image.open(os.path.join(dirpath, name)))\n",
    "                    if ppn==comparison_base_ppn:\n",
    "                        base_jpgFilePaths.append((physicalID,os.path.join(dirpath, name),hash))\n",
    "                    else:\n",
    "                        jpgFilePaths[ppn].append((physicalID,os.path.join(dirpath, name),hash))\n",
    "printLog(\"Done.\")                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "unexpected-preference",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import DistanceMetric\n",
    "dist = DistanceMetric.get_metric('hamming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "coordinated-strip",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPN745219993 with 10 pages and 10 fulltext files.\n",
      "PPN745232752 with 10 pages and 10 fulltext files.\n",
      "PPN745219993_copy with 10 pages and 10 fulltext files.\n",
      "PPN745236499 with 10 pages and 10 fulltext files.\n",
      "Total pages: 40\n"
     ]
    }
   ],
   "source": [
    "totalPages=0\n",
    "for ppn in dirsPerPPN:\n",
    "    l=len(dirsPerPPN[ppn])\n",
    "    l_fulltext=0\n",
    "    if ppn==comparison_base_ppn:\n",
    "        l_fulltext=len(base_fulltextFilePaths)\n",
    "    else:\n",
    "        l_fulltext=len(fulltextFilePaths[ppn])\n",
    "    print(\"%s with %i pages and %i fulltext files.\"%(ppn,l,l_fulltext))\n",
    "    totalPages+=l\n",
    "print(\"Total pages: %i\"%totalPages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "infrared-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "iframe_references=[]\n",
    "# create the overview for the comparison base\n",
    "# we have to sort the file path by their physical ID before output\n",
    "base_sorted_by_physID = sorted(base_jpgFilePaths, key=lambda tup: tup[0])\n",
    "html=\"<body style='background-color:grey;'>\"\n",
    "for phys_id,file_path,hash_val in base_sorted_by_physID:\n",
    "    html+=\"<img src='\"+file_path+\"' width='150px' alt='\"+phys_id+\"'/>\\n\"\n",
    "html+=\"</body>\"\n",
    "\n",
    "f = open(basePath+\"base_overview_\"+ppn+\".html\", \"w\")\n",
    "f.write(html)\n",
    "f.close()\n",
    "\n",
    "iframe_references.append(basePath+\"base_overview_\"+ppn+\".html\")\n",
    "\n",
    "for ppn in jpgFilePaths:\n",
    "    # we have to sort the file path by their physical ID before output\n",
    "    sorted_by_physID = sorted(jpgFilePaths[ppn], key=lambda tup: tup[0])\n",
    "    html=\"\"\n",
    "    for i,v in enumerate(sorted_by_physID):\n",
    "        phys_id,file_path,hash_val=v\n",
    "        html+=\"<img src='\"+file_path+\"' width='150px' alt='\"+phys_id+\"'/>\\n\"\n",
    "        hash_diff=base_sorted_by_physID[i][2]-hash_val\n",
    "        html+=str(hash_diff)\n",
    "\n",
    "    f = open(basePath+\"overview_\"+ppn+\".html\", \"w\")\n",
    "    f.write(html)\n",
    "    f.close()\n",
    "    \n",
    "    iframe_references.append(basePath+\"overview_\"+ppn+\".html\")\n",
    "\n",
    "html=\"\"\n",
    "for iframe in iframe_references: \n",
    "    html+=\"<iframe src='\"+iframe+\"'' width='100%' height='260px'></iframe> <br />\"\n",
    "\n",
    "f = open(basePath+\"comparison.html\", \"w\")\n",
    "f.write(html)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "agricultural-submission",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iframe_references=[]\n",
    "\n",
    "# the window surrounding the current page that will be used for comparisons\n",
    "# the window has to be uneven as it will consist of the pages before and after the current page\n",
    "comparison_window=5\n",
    "# only uneven windows are allowed\n",
    "if comparison_window%2==0:\n",
    "    comparison_window+=1\n",
    "\n",
    "window_offset=comparison_window//2\n",
    "max_len=len(base_sorted_by_physID)\n",
    "\n",
    "# for debug purposes only\n",
    "# dummy_list=(\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\")\n",
    "\n",
    "\n",
    "# the window will be constructed as follows:\n",
    "#           /-------comparison_window-----\\\n",
    "# [...][lower_bound][ ][current_pos][ ][upper_bound][...] \n",
    "#\n",
    "# the lower and upper bound will never be outside the array bounds\n",
    "\n",
    "other_ppn=\"PPN745232752\"\n",
    "other_ppn=\"PPN745236499\"\n",
    "# debug\n",
    "#other_ppn=\"PPN745219993_copy\"\n",
    "sorted_by_physID = sorted(jpgFilePaths[other_ppn], key=lambda tup: tup[0])\n",
    "\n",
    "for current_pos in range(0,max_len):\n",
    "    # restrict lower/upper bound to the array bounds\n",
    "    lower_bound=max(current_pos-window_offset,0)\n",
    "    upper_bound=min(current_pos+window_offset,max_len)\n",
    "    #print(current_pos)\n",
    "    #print(\"\\t lower %i, upper %i\"%(lower_bound,upper_bound))\n",
    "    #print(\"\\t\"+str(dummy_list[lower_bound:upper_bound+1]))\n",
    "    \n",
    "    # TODO: bound check for other\n",
    "    \n",
    "    base_hashes=np.array(base_sorted_by_physID[current_pos][2])\n",
    "    other_hashes=np.array([tuple_element[2] for tuple_element in sorted_by_physID[lower_bound:upper_bound+1]])\n",
    "    other_paths=np.array([tuple_element[1] for tuple_element in sorted_by_physID[lower_bound:upper_bound+1]])\n",
    "    other_phys_ids=np.array([tuple_element[0] for tuple_element in sorted_by_physID[lower_bound:upper_bound+1]])\n",
    "    hash_diffs=base_hashes-other_hashes\n",
    "    # normalize hash diffs; max. hamming distance is 8*8\n",
    "    hash_diffs=hash_diffs/64\n",
    "    \n",
    "    base_phys_id_nr=int(base_sorted_by_physID[current_pos][0])\n",
    "    html=\"<img src='\"+base_sorted_by_physID[current_pos][1]+\"' width='150px' />'\"\n",
    "    html+=\"<p>\"+str(base_phys_id_nr)+\"</p><br />\"\n",
    "    \n",
    "    for i,diff in enumerate(hash_diffs):\n",
    "        phys_id_nr=int(other_phys_ids[i])\n",
    "        distance_multiplicator=max(math.log(abs(base_phys_id_nr-phys_id_nr)+1),1)\n",
    "        html+=\"<img src='\"+other_paths[i]+\"' width='150px' /> \"+\"δ: \"+str(diff*distance_multiplicator)#+\" phys. ID:\"+str(phys_id_nr)+\" : \"+str(distance)\n",
    "    \n",
    "    outPath=basePath+\"diff_current_\"+str(current_pos)+\".html\"\n",
    "    iframe_references.append(outPath)\n",
    "    f = open(outPath, \"w\")\n",
    "    f.write(html)\n",
    "    f.close()\n",
    "# base_jpgFilePaths.append((physicalID,os.path.join(dirpath, name),hash))\n",
    "# jpgFilePaths[ppn].append((physicalID,os.path.join(dirpath, name),hash))\n",
    "\n",
    "html=\"\"\n",
    "for iframe in iframe_references: \n",
    "    html+=\"<iframe src='\"+iframe+\"'' width='100%' height='260px'></iframe> <br />\"\n",
    "\n",
    "f = open(basePath+\"comparison_matching.html\", \"w\")\n",
    "f.write(html)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-miracle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-mortality",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-vanilla",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
