{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "man lernt\n",
    "* screenscraping in der wikipedia (vertrautheit mit HTML hilfreich, aber keine voraussetzung)\n",
    "* erzeugung von tabularen daten aus wenig strukturierten inhalten der Wikipedia\n",
    "* was ist eine prozedur/methode\n",
    "* netzwerkanalyse\n",
    "* export data to visualize it in a \"normal\" website using the D3.js library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The %... is an iPython thing, and is not part of the Python language.\n",
    "# In this case we're just telling the plotting library to draw things on\n",
    "# the notebook, instead of on a separate window.\n",
    "%matplotlib inline\n",
    "# See all the \"as ...\" contructs? They're just aliasing the package names.\n",
    "# That way we can call methods like plt.plot() instead of matplotlib.pyplot.plot().\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import OrderedDict # provides the ordered dictionary\n",
    "import re # for regular expressions used below\n",
    "import urllib # to read from URLs\n",
    "import networkx as nx # network analysis\n",
    "import itertools\n",
    "from datetime import datetime # for time measurement\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find the documentation of the Wikipedia package [_here_](https://pypi.python.org/pypi/wikipedia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import wikipedia as wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no longer needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!pip install html2text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no longer needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import xml.etree.ElementTree as ET\n",
    "#import html2text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "page = wiki.page(\"batman\")\n",
    "#page = wiki.page(\"catwoman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Anaconda comes with _Beautiful Soup_, a library for screen-scraping [documentation](http://www.crummy.com/software/BeautifulSoup/bs4/doc/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from bs4 import BeautifulSoup\n",
    "\n",
    "# Beautiful Soup needs the HTML of the Wikipedia page\n",
    "#html_doc=page.html()\n",
    "#soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tables=soup.find_all('table',class_=\"infobox\")\n",
    "#infoboxTable=tables[0] # fill fail if no infobox is presented, will be fixed later\n",
    "#print infoboxTable.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we expect the following _th_ elements as seperators\n",
    "* <th scope=\"row\" style=\"width: 40%;\">Alter ego</th>\n",
    "* <th scope=\"row\" style=\"width: 40%;\">Team affiliations</th>\n",
    "* <th scope=\"row\" style=\"width: 40%;\">Partnerships</th>\n",
    "* <th scope=\"row\" style=\"width: 40%;\">Notable aliases</th>\n",
    "* <th scope=\"row\" style=\"width: 40%;\">Abilities</th>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rows=infoboxTable.find_all(\"tr\")\n",
    "#for row in rows:\n",
    "#    if row.th is not None:\n",
    "#        print row.th.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More on [_regular expressions_](https://docs.python.org/2/howto/regex.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#abilityRow=None\n",
    "#partnerRow=None\n",
    "#firstAppearance=\"\"\n",
    "#p = re.compile('\\d\\d\\d\\d') # we expect the year to have four digits\n",
    "\n",
    "#for row in rows:\n",
    "#    if row.th is not None and row.th.string == \"First appearance\":\n",
    "#        rawText=row.td.get_text()\n",
    "#        m = p.search(rawText)\n",
    "#        firstAppearance=m.group()\n",
    "#    elif row.th is not None and row.th.string == \"Abilities\":\n",
    "#        abilityRow=row\n",
    "#    elif row.th is not None and row.th.string == \"Partnerships\":\n",
    "#        partnerRow=row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# as not every page has a \"complete\" infobox, we have to check the presence of abilities and partnerships\n",
    "#abilities=[]\n",
    "#if abilityRow is not None:\n",
    "#    li=abilityRow.find_all(\"li\")\n",
    "#    for l in li:\n",
    "        # check if an anchor (a link to a website) is contained\n",
    "#        if l.a is not None:\n",
    "            # if so, discard the link and keep the plain text\n",
    "#            l.a.unwrap()\n",
    "#        abilities.append(l.get_text().strip())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#partnerships=[]\n",
    "#if partnerRow is not None:\n",
    "#    partners=partnerRow.find_all(\"a\")\n",
    "#    for p in partners:\n",
    "#        partnerships.append(p.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for a in abilities:\n",
    "#    print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for p in partnerships:\n",
    "#    print p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print firstAppearance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, we will define a procedure/sub-routine for later usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractData(myDoc):\n",
    "    soup = BeautifulSoup(myDoc, 'html.parser')\n",
    "    #print soup.title\n",
    "    tables=soup.find_all('table',class_=\"infobox\")\n",
    "    # if there is no infobox, ignore the page\n",
    "    if len(tables)>=1:\n",
    "        infoboxTable=tables[0]\n",
    "        # try to get the name of the character\n",
    "        if infoboxTable.tr.th is not None:\n",
    "            name=infoboxTable.tr.th.get_text()\n",
    "        else:\n",
    "            name=\"N/A\"\n",
    "        abilityRow=None\n",
    "        partnerRow=None\n",
    "        firstAppearance=\"2020\" # dummy entry in case the \"first appearance\" entry is missing\n",
    "        abilities=[]\n",
    "        partnerships=[]\n",
    "        \n",
    "        # image processing\n",
    "        if infoboxTable.find('img'):\n",
    "            articleImage=infoboxTable.find('img')[\"src\"]\n",
    "        else:\n",
    "            articleImage=None\n",
    "\n",
    "        p = re.compile('\\d\\d\\d\\d') # we expect the year of first appearance to have four digits\n",
    "        \n",
    "        rows=infoboxTable.find_all(\"tr\")\n",
    "        for row in rows:\n",
    "            if row.th is not None and row.th.string == \"First appearance\":\n",
    "                rawText=row.td.get_text()\n",
    "                m = p.search(rawText)\n",
    "                # deal with missing years of first appearance\n",
    "                if m:\n",
    "                    firstAppearance=m.group()\n",
    "            elif row.th is not None and row.th.string == \"Abilities\":\n",
    "                abilityRow=row\n",
    "            elif row.th is not None and row.th.string == \"Partnerships\":\n",
    "                partnerRow=row\n",
    "\n",
    "        # as not every page has a \"complete\" infobox, we have to check the presence of abilities and partnerships\n",
    "        if abilityRow is not None:\n",
    "            li=abilityRow.find_all(\"li\")\n",
    "            for l in li:\n",
    "                # check if an anchor (a link to a website) is contained\n",
    "                if l.a is not None:\n",
    "                    # if so, discard the link and keep the plain text\n",
    "                    l.a.unwrap()\n",
    "                abilities.append(l.get_text().strip())\n",
    "        # a fix for abilities without the ul/li structure\n",
    "            if len(li)==0:\n",
    "                rawStr=str(abilityRow.td)\n",
    "                rawStr=rawStr.replace(\"<td>\",\"\").replace(\"</td>\",\"\").replace(\"\\n\",\"\").strip()\n",
    "                # abilities are sometimes separated by  <br/>, a comma, a period, or \"and\"\n",
    "                rawStr=rawStr.replace(\"<br/>\",\";\")\n",
    "                rawStr=rawStr.replace(\",\",\";\")\n",
    "                rawStr=rawStr.replace(\".\",\";\")\n",
    "                # we have to treat 'and' in a special way as it may be contained as a substring in \"normal\" words\n",
    "                #rawStr=rawStr.replace(\"and\",\";\")\n",
    "                rawTokens=rawStr.split(\" and \")\n",
    "                rawStr=\";\".join(rawTokens)\n",
    "                # remove all other HTML tags\n",
    "                p2 = re.compile(r'<.*?>')\n",
    "                rawStr=p2.sub(' ', rawStr)\n",
    "                # clean whitespaces surrounding the string\n",
    "                rawStr.strip()\n",
    "                rawTokens=rawStr.split(\";\")\n",
    "                for t in rawTokens:\n",
    "                    t=t.strip()\n",
    "                    # we have to ignore additional noise such as the following \"abilities\"\n",
    "                    if t.lower()==\"see below\":\n",
    "                        pass\n",
    "                    elif t.lower()==\"various\":\n",
    "                        pass\n",
    "                    elif t.lower()==\"varies\":\n",
    "                        pass\n",
    "                    elif t.lower()==\"none\":\n",
    "                        pass\n",
    "                    else:\n",
    "                        if str(t):\n",
    "                            abilities.append(str(t))\n",
    "\n",
    "        if partnerRow is not None:\n",
    "            partners=partnerRow.find_all(\"a\")\n",
    "            for p in partners:\n",
    "                partnerships.append(p.string)\n",
    "\n",
    "        \n",
    "        \n",
    "        result=dict()\n",
    "        result[\"name\"]=name\n",
    "        result[\"firstAppearance\"]=int(firstAppearance)\n",
    "        result[\"abilities\"]=abilities\n",
    "        result[\"abilitiesCount\"]=len(abilities)\n",
    "        result[\"partnerships\"]=partnerships\n",
    "        result[\"partnershipsCount\"]=len(partnerships)\n",
    "        if articleImage:\n",
    "            result[\"imageURL\"]=\"https:\"+str(articleImage)\n",
    "        else:\n",
    "            result[\"imageURL\"]=\"https://None\"\n",
    "        #print abilities\n",
    "        return result\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html_doc=urllib.urlopen(\"https://en.wikipedia.org/wiki/El_Diablo_(comics)\")\n",
    "r=extractData(html_doc)\n",
    "print r\n",
    "\n",
    "print \"\\n NEXT\\n\"\n",
    "\n",
    "html_doc=urllib.urlopen(\"https://en.wikipedia.org/wiki/Batman\")\n",
    "r=extractData(html_doc)\n",
    "print r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "methodenaufruf erklären"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r=extractData(html_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "page.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page=wiki.page(\"Category:DC_Comics_superheroes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categoryPages=[]\n",
    "# DC superheroes\n",
    "categoryPages.append(\"https://en.wikipedia.org/w/index.php?title=Category:DC_Comics_superheroes&pageuntil=Dragon+King%0ADragon+King+%28DC+Comics%29#mw-pages\")\n",
    "categoryPages.append(\"https://en.wikipedia.org/w/index.php?title=Category:DC_Comics_superheroes&pagefrom=Krypto#mw-pages\")\n",
    "categoryPages.append(\"https://en.wikipedia.org/w/index.php?title=Category:DC_Comics_superheroes&pagefrom=Robin%0ARobin+%28comics%29#mw-pages\")\n",
    "categoryPages.append(\"https://en.wikipedia.org/w/index.php?title=Category:DC_Comics_superheroes&pagefrom=XS+%28comics%29#mw-pages\")\n",
    "\n",
    "# general DC characters\n",
    "#categoryPages.append(\"https://en.wikipedia.org/w/index.php?title=Category:DC_Comics_characters&pageuntil=Smoak%2C+Felicity%0AFelicity+Smoak#mw-pages\")\n",
    "#categoryPages.append(\"https://en.wikipedia.org/w/index.php?title=Category:DC_Comics_characters&pagefrom=Smoak%2C+Felicity%0AFelicity+Smoak#mw-pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "<div id=\"mw-pages\">\n",
    "```\n",
    "wird gesucht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getSuperheroes(myCategories,myDictionary):\n",
    "    for c in myCategories:\n",
    "    # ignore <a class=\"mw-redirect\"> as they redirect into articles, \n",
    "    # to be precise, we only consider <a> tags without a class atrribute \n",
    "    # because we are only interested in superheroes with distinct wikipedia articles\n",
    "        items=c.ul.find_all(\"li\")\n",
    "        for item in items:\n",
    "            if item.a.get(\"class\") is None:\n",
    "                myDictionary[item.a[\"title\"]]=item.a[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "startTime=datetime.now()\n",
    "print \"Fetching superhero URLs...\"\n",
    "sys.stdout.flush() # forces to output the result of the print command immediately, see: http://stackoverflow.com/questions/230751/how-to-flush-output-of-python-print\n",
    "\n",
    "superheroes=OrderedDict() # we use an ordered dict here because we want to preserve the order items were added\n",
    "for catPage in categoryPages:\n",
    "    html_doc=urllib.urlopen(catPage)\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    categories=soup.select(\"#mw-pages\")[0].select(\".mw-category-group\")\n",
    "    getSuperheroes(categories,superheroes) # we pass the superheroes dictionary on to merge the heroes extracted from all pages\n",
    "\n",
    "duration=datetime.now()-startTime\n",
    "print \"Processing completed in \"+str(duration)+\".\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checken, da ursprünglich characters abgefragt wurden: __Relationship of Clark Kent and Lois Lane__ is obviously no superhero but we have to deal with it later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap Things Up\n",
    "\n",
    "the processing will take a while, i.e., 3-4 minutes on my notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wikiBaseURL=\"https://en.wikipedia.org\"\n",
    "heroFeats=[]\n",
    "i=0;\n",
    "countItems=len(superheroes)\n",
    "\n",
    "print \"Processing \"+str(countItems)+\" Wikipedia pages and downloading images. This will take a while...\"\n",
    "sys.stdout.flush() # forces to output the result of the print command immediately, see: http://stackoverflow.com/questions/230751/how-to-flush-output-of-python-print\n",
    "\n",
    "startTime=datetime.now()\n",
    "\n",
    "\n",
    "for key, value in superheroes.iteritems():\n",
    "    i=i+1\n",
    "    wikiURL=wikiBaseURL+value\n",
    "    #print \"Processing \"+wikiURL+\" ; \"+str(i)+\" of \"+str(countItems)\n",
    "    html_doc=urllib.urlopen(wikiURL)\n",
    "    r=extractData(html_doc)\n",
    "    if r:\n",
    "        r[\"url\"]=wikiURL\n",
    "        heroFeats.append(r)\n",
    "    else:\n",
    "        print \"\\t\"+wikiURL+\" does not contain an infobox. Processing aborted.\"\n",
    "\n",
    "duration=datetime.now()-startTime\n",
    "print \"Processing completed in \"+str(duration)+\".\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the download takes approx. 2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Downloading images. This will take a while...\"\n",
    "sys.stdout.flush() # forces to output the result of the print command immediately, see: http://stackoverflow.com/questions/230751/how-to-flush-output-of-python-print\n",
    "\n",
    "startTime=datetime.now()\n",
    "# downloading images\n",
    "imagePath=\"./img.dc_chars/\"\n",
    "\n",
    "if not os.path.exists(imagePath):\n",
    "    os.makedirs(imagePath)\n",
    "\n",
    "for i,hero in enumerate(heroFeats):\n",
    "    hero[\"localFilePath\"]=\"N/A\" # caveat wg. JSON http://stackoverflow.com/questions/13715891/d3-json-uncaught-typeerror-cannot-read-property-children-of-undefined\n",
    "    iURL=hero[\"imageURL\"]\n",
    "    if not iURL==\"https://None\":\n",
    "        tokens=iURL.split(\".\")\n",
    "        suffix=tokens[-1]\n",
    "        localFilePath=imagePath+str(i)+\".\"+suffix\n",
    "        hero[\"localFilePath\"]=localFilePath\n",
    "        try:\n",
    "            urllib.urlretrieve(iURL,localFilePath)\n",
    "        except IOError: # if we would catch all other exception, we would have a hard time to stop the kernel at all\n",
    "            print \"Downloading error while accessing: \"+hero[\"imageURL\"]\n",
    "duration=datetime.now()-startTime\n",
    "print \"Downloading completed in \"+str(duration)+\".\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as the processing took a while, it would be handy to save the result, in order to do so, we will create a pandas [DataFrame](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) out of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rows=[]\n",
    "columns=[\"Name\",\"Year\",\"Abilities\",\"AbilitiesCount\",\"Partnerships\",\"PartnershipsCount\",\"URL\",\"ImageURL\",\"localFilePath\"]\n",
    "\n",
    "for hero in heroFeats:\n",
    "    rowx=[]\n",
    "    rowx.append(hero[\"name\"])\n",
    "    rowx.append(hero[\"firstAppearance\"])\n",
    "    rowx.append(\",\".join(hero[\"abilities\"]))\n",
    "    rowx.append(hero[\"abilitiesCount\"])\n",
    "    rowx.append(\",\".join(hero[\"partnerships\"]))\n",
    "    rowx.append(hero[\"partnershipsCount\"])\n",
    "    rowx.append(hero[\"url\"])\n",
    "    rowx.append(hero[\"imageURL\"])\n",
    "    rowx.append(hero[\"localFilePath\"])\n",
    "    rows.append(rowx)\n",
    "\n",
    "df=pd.DataFrame(rows,columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to save it to disk, a CSV file is a possible solution; ? operator erklären"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.to_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have to pass the encoding parameter as our data frame contains Unicode data, \"\\t\" as separator because of the commas we used to separate the abilities etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('dc_superheroes.csv',index=False,header=True,encoding='utf-8', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuing the Analysis\n",
    "later, we could read the data again with [read_csv()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('dc_superheroes.csv',encoding='utf-8', sep=\"\\t\",dtype={\"Partnerships\":'str'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the \"lonely\" superheroes\n",
    "df2=df[df[\"Partnerships\"].isnull()]\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the \"sociable\" superheroes\n",
    "df3=df[df[\"Partnerships\"].notnull()]\n",
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df['Year']==df['Year'].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply-statement erklären"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['Year'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['PartnershipsCount'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['AbilitiesCount'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df['AbilitiesCount']==df['AbilitiesCount'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df['AbilitiesCount']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# docs: http://matplotlib.org/api/text_api.html#matplotlib.text.Annotation\n",
    "#fig = plt.figure()\n",
    "df.groupby(\"Year\").mean().plot()\n",
    "MaxValue = df['Year'].max()\n",
    "plt.annotate('My Text', xy=(1000, 5),xytext=(100, 10),arrowprops=dict(arrowstyle=\"->\",connectionstyle=\"arc3\"),textcoords='figure points')\n",
    "plt.show()\n",
    "#plt.annotate('My Text', xy=(0.5, 0), xycoords='figure fraction',xytext=(0.5, 0.5), textcoords='figure fraction',arrowprops=dict(arrowstyle=\"->\",connectionstyle=\"arc3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[(df.Year>=1939) & (df.Year<1945)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Red Tornado ist \"great cook\"\n",
    "\n",
    "* https://en.wikipedia.org/wiki/Onslaught_(DC_Comics) checken, interessant wegen Jihad (reiner Zufall, wäre ja jetzt eher Thema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to avoid spelling issues, we capitalize all superheroes' names\n",
    "# lambda Konzept erläutern\n",
    "df['NameCaps'] = df.Name.apply(lambda x: x.upper())\n",
    "df['PartnershipsCaps'] = df.Partnerships.astype(str).apply(lambda x: x.upper())\n",
    "df['AbilitiesCaps'] = df.Abilities.astype(str).apply(lambda x: x.upper())\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIMIT THE SIZE OF DF!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df=df[(df.Year>=1970) & (df.Year<1971)]\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create an empty graph from the nx (networkx) package imported above\n",
    "G=nx.Graph()\n",
    "G_abilities=nx.Graph()\n",
    "\n",
    "# .itertuples() gives us an iterator over all rows in a data frame\n",
    "for row in df.itertuples():\n",
    "    hero=row[10]\n",
    "    if not hero in G.nodes():\n",
    "        G.add_node(hero)\n",
    "        # the name attribute will be helpful for D3.js visualizations\n",
    "        G.node[hero]['name'] = hero\n",
    "        G.node[hero]['picture']=row[8]\n",
    "        localFilePath=str(row[9])\n",
    "        if not localFilePath.upper()==\"NAN\":\n",
    "            G.node[hero]['localFilePath']=localFilePath\n",
    "        else:\n",
    "            G.node[hero]['localFilePath']=\"N/A\" # must not be left empty, otherwise corrupt JSON will be created below\n",
    "        \n",
    "    if not hero in G_abilities.nodes():\n",
    "        G_abilities.add_node(hero)\n",
    "        G_abilities.node[hero]['name'] = hero\n",
    "        G_abilities.node[hero]['group'] = 2 # will change the display color in D3.js\n",
    "        G_abilities.node[hero]['picture']=row[8]\n",
    "        localFilePath=str(row[9])\n",
    "        if not localFilePath.upper()==\"NAN\":\n",
    "            G_abilities.node[hero]['localFilePath']=localFilePath\n",
    "        else:\n",
    "            G_abilities.node[hero]['localFilePath']=\"N/A\" # must not be left empty, otherwise corrupt JSON will be created below\n",
    "        \n",
    "    # treat partnerships  (PartnershipsCount)  \n",
    "    if row[6]: # a shortcut to find out whether a string is empty\n",
    "        if not row[11]==\"NAN\":\n",
    "            partners=row[11].split(\",\")\n",
    "            for partner in partners:\n",
    "                if not partner in G.nodes():\n",
    "                    G.add_node(partner)\n",
    "                    G.node[partner]['name'] = partner\n",
    "                G.add_edge(hero,partner)\n",
    "    # treat abilities\n",
    "    if row[4]: #AbilitiesCount\n",
    "        if not row[12]==\"NAN\":\n",
    "            abilities=row[12].split(\",\")\n",
    "            for ab in abilities:\n",
    "                if not ab in G_abilities.nodes():\n",
    "                    G_abilities.add_node(ab)\n",
    "                    G_abilities.node[ab]['name'] = ab\n",
    "                    G_abilities.node[ab]['group'] = 1 # will change the display color in D3.js\n",
    "                G_abilities.add_edge(hero,ab)\n",
    "                #print \"Adding edge: \"+hero+\" - \"+str(ab)\n",
    "            #G_abilities.add_edges_from(list(itertools.product(abilities,abilities))) # macht ein cross product der abilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print G.number_of_nodes()\n",
    "print G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print G_abilities.number_of_nodes()\n",
    "print G_abilities.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.draw_spring(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from networkx.algorithms.shortest_paths.generic import all_shortest_paths\n",
    "f=all_shortest_paths(G,\"BATMAN\",\"THE JOKER\")\n",
    "print([p for p in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "li=['BATMAN', 'HUNTRESS (HELENA WAYNE)', u'POWER GIRL', 'HARLEY QUINN', 'THE JOKER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from networkx.algorithms.assortativity.neighbor_degree import average_neighbor_degree\n",
    "average_neighbor_degree(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df.NameCaps==\"BIZARRA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weitere Ideen\n",
    "\n",
    "* mit Google nGrams abgleichen? https://books.google.com/ngrams/graph?content=Skilled%2C+magic&case_insensitive=on&year_start=1963&year_end=1965&corpus=16&smoothing=3&share=&direct_url=t4%3B%2CSkilled%3B%2Cc0%3B%2Cs0%3B%3Bskilled%3B%2Cc0%3B%3BSkilled%3B%2Cc0%3B.t4%3B%2Cmagic%3B%2Cc0%3B%2Cs0%3B%3Bmagic%3B%2Cc0%3B%3BMagic%3B%2Cc0%3B%3BMAGIC%3B%2Cc0\n",
    "\n",
    "* x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Data in Your Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from networkx.readwrite import json_graph\n",
    "\n",
    "#d = json_graph.node_link_data(G)\n",
    "d = json_graph.node_link_data(G_abilities)\n",
    "json.dump(d, open('./force/force.json','w'))\n",
    "\n",
    "# weitere notwendige Files für D3.js visualization unter: /Users/david/Documents/src/javascript/visualization\n",
    "# examples taken from https://github.com/networkx/networkx/tree/master/examples/javascript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erklärungsversuche\n",
    "\n",
    "* The first Green Lantern character, Alan Scott, was created in 1940 during the initial popularity of superheroes. Alan Scott usually fought common criminals in New York City with the aid of his magic ring. The publication of this character ceased in 1949 during a general decline in the popularity of superhero comics, but the character saw a limited revival in later decades.\n",
    "\n",
    "* After World War II the popularity of superheroes in general declined. The Green Lantern comic book was cancelled with issue #38 (May–June 1949), and All Star Comics #57 (1951) was the character's last Golden Age appearance. When superheroes came back in fashion in later decades, Alan Scott was revived, but was forever marginalized by the new Hal Jordan character who had been created to supplant him (see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import http_server\n",
    "http_server.load_url('force/force.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* niemals \"interrupt kernel\" zum beenden wählen, sonst muss man das gesamte notebook shutdown machen, da der webserver sonst nicht mehr den port 8000 freigibt, zum stop immer \"enter\" drücken\n",
    "* http_server.pyc muss gelöscht werden, wenn man etwas an http_server.py ändert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
